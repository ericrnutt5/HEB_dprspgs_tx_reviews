{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow for Analyzing Common Words in Negative Store Reviews\n",
    "### Created by Eric Nutt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.collocations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_word = stopwords.words('english')\n",
    "stop_word_upper = []\n",
    "for word in stop_word:\n",
    "    stop_word_upper.append(word.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define function for reading Google Maps store reviews .csv into a simple pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for importing csv to pandas dataframe\n",
    "\n",
    "def import_review_csv(csv_path):\n",
    "    \"\"\"Imports a csv of store reviews, creates a dataframe, adds year column and indexes on it\n",
    "\n",
    "    Paramaters\n",
    "    ----------\n",
    "    file_path : string\n",
    "        Path to file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    returned_data : dataframe\n",
    "        Dataframe created from loaded csv\n",
    "    \"\"\"\n",
    "    # Read csv as dataframe\n",
    "    df = pd.read_csv(csv_path)\n",
    "    # Convert date coloumn to datetime\n",
    "    df['review_datetime_utc'] = pd.to_datetime(df['review_datetime_utc'])\n",
    "    # Remove timestamp from Date and store it in a new column\n",
    "    df['Date'] = df['review_datetime_utc'].dt.date\n",
    "    # Set the index to the DATE column\n",
    "    df2 = df.set_index('Date')\n",
    "    # Keep only author_title, review_text, review_rating, review_datetime_utc\n",
    "    df3 = df2[['author_title', 'review_text', 'review_rating']]\n",
    "    # Drop rows with NaN values (not comment left with rating)\n",
    "    df4 = df3.dropna(axis=0, how='any', thresh=None,\n",
    "                     subset=None, inplace=False)\n",
    "    # Convert index to datetime\n",
    "    df4.index = pd.to_datetime(df4.index)\n",
    "    # Parse dates for year index\n",
    "    df5 = df4.sort_index()\n",
    "    return df5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply workflow to Dripping Springs HEB store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_title</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-10-07</th>\n",
       "      <td>Helen Gilliam</td>\n",
       "      <td>I will give you the good news first, I have be...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-20</th>\n",
       "      <td>MaryClare Porter</td>\n",
       "      <td>I am very disapointed at the customer service ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-09</th>\n",
       "      <td>michele Peel</td>\n",
       "      <td>FYI...I live in Wimberley but do most of my bu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-30</th>\n",
       "      <td>Rick Lose</td>\n",
       "      <td>Too small and crowded</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-29</th>\n",
       "      <td>billy smith</td>\n",
       "      <td>Really busy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                author_title  \\\n",
       "Date                           \n",
       "2015-10-07     Helen Gilliam   \n",
       "2016-08-20  MaryClare Porter   \n",
       "2017-05-09      michele Peel   \n",
       "2017-05-30         Rick Lose   \n",
       "2017-06-29       billy smith   \n",
       "\n",
       "                                                  review_text  review_rating  \n",
       "Date                                                                          \n",
       "2015-10-07  I will give you the good news first, I have be...              2  \n",
       "2016-08-20  I am very disapointed at the customer service ...              2  \n",
       "2017-05-09  FYI...I live in Wimberley but do most of my bu...              1  \n",
       "2017-05-30                              Too small and crowded              1  \n",
       "2017-06-29                                        Really busy              1  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define path to csv reviews for HEB Dripping Springs\n",
    "heb_dstx_path = 'heb_dstx_reviews.csv'\n",
    "\n",
    "heb_dpsp_tx_df = import_review_csv(heb_dstx_path)\n",
    "heb_dpsp_tx_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply workflow to Waxahachie HEB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nheb_wax_path = 'heb_waxtx_reviews.csv'\\n\\nheb_wax_tx_df = import_review_csv(heb_wax_path)\\nheb_wax_tx_df.head()\\n\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define path to csv reviews for HEB Dripping Springs\n",
    "'''\n",
    "heb_wax_path = 'heb_waxtx_reviews.csv'\n",
    "\n",
    "heb_wax_tx_df = import_review_csv(heb_wax_path)\n",
    "heb_wax_tx_df.head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define function for generating common words list.\n",
    "This function will generate a list of the most common words (ommiting stopwords) with a word count. I've applied this function to the dataframes for two HEB stores: Dripping Springs and Waxahachie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write function to get most common words without stop words\n",
    "\n",
    "# Define function for getting most common meaningful words\n",
    "def most_common_words(store_df):\n",
    "    \"\"\"Reads review text column and gets most common words without stopwords\n",
    "\n",
    "    Paramaters\n",
    "    ----------\n",
    "    store_df : pandas dataframe\n",
    "        store dataframe\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    returned_data : list\n",
    "        list of most common words in review text\n",
    "    \"\"\"\n",
    "    # Exclude stopwords with Python's list comprehension and pandas.DataFrame.apply.\n",
    "    store_df['review_without_stopwords'] = store_df['review_text'].apply(\n",
    "        lambda x: ' '.join([word for word in x.split() if word not in (stop_word) and word not in (stop_word_upper)]))\n",
    "    # Get most common words from review text\n",
    "    common_words = Counter(\" \".join(\n",
    "        store_df[\"review_without_stopwords\"].str.lower()).split()).most_common(100)\n",
    "    return common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function on Dripping Springs df\n",
    "heb_dpsp_df = most_common_words(heb_dpsp_tx_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function on Waxahachie df\n",
    "# most_common_words(heb_wax_tx_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary & Conclusions\n",
    "The workflow above reads a .csv of google maps store reviews into a dataframe with the columns: date of review, review author, review text, and review rating (stars). A function is then applied to that new dataframe to get the most common words (ommiting stopwords) for a more efficient analysis of the review text.\n",
    "\n",
    "\n",
    "#### Dripping Springs, HEB\n",
    "\"Rude\" shows up eight times in 46 reviews. One of HEB's most important values is \"Heart\". At HEB, people matter and are at the heart of every decision made. I've experienced exemplary customer service whenever I go into an HEB, and I know that instances of employees being rude to customers is the exception not the norm. However, I believe any and all customer concerns should be given their due diligence, so one might look further into these reviews. \n",
    "\n",
    "Furthermore, \"Diane\" shows up five times. Without speaking to Diane, I am unable to comment on the situation. That being said, their name showing up five times in one and two star reviews isn't necessarily a good thing. Perhaps reviewing the importance of HEB's values with Diane would be a step in the right direction.\n",
    "\n",
    "\n",
    "#### Waxahachie, HEB\n",
    "\"Cake/Cakes/Cup\" shows up a combined 34 times in 97 reviews. A one-off negative review of the bakery department could be chalked up to the employee or customer having a bad day, and not be indicative of a persistant concern. However, 34 times seems especially high, therefore this could, and probably should, be looked further into. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['give', 'good', 'news', 'first', ',', 'delighted', 'heb', 'indripping', 'springs', '.'], ['in', 'last', 'month', 'six', 'weeks', 'seen', 'steady', 'decline', 'produce', 'offered', '.'], ['it', 'appaling', 'went', 'yesterday', '10/6/15', '.'], ['short', 'supplies', ',', 'old', 'wrinkled', 'veggies', ',', 'chaos', 'trying', 'reah', 'wanted', '.'], ['every', 'week', 'go', 'buy', 'apples', ',', 'usually', 'six', 'different', 'variety', 'week', 'last', 'four', 'weeks', 'least', 'half', 'apples', 'bad', 'cut', 'them', '.'], ['they', 'cheap', 'consider', 'expensive', 'deer', 'food', '.'], ['you', 'stopped', 'carrying', 'taylor', 'farms', 'bag', 'salads', 'put', 'nowhere', 'near', 'good', '.'], ['thought', 'let', 'know', 'also', 'let', 'know', 'many', 'others', 'unhappy', '.'], ['we', 'always', 'bragged', 'heb', 'much', 'brag', 'now', '.'], ['another', 'thing', 'noticed', 'well', 'two', 'months', 'can', 'not', 'get', 'party', 'size', 'fritos', ',', 'go', 'walmart', 'those', ',', 'stop', 'coming', 'disappointed', '.'], ['hank', 'you', ',', 'helen', 'g', '.']]\n",
      "\n",
      "[['disapointed', 'customer', 'service', 'late', '.'], ['for', 'past', 'several', 'months', 'bag', 'groceries', 'everytime', '.'], ['this', 'evening', 'working', 'day', 'driving', 'hour', 'home', 'work', ',', 'stop', 'shopping', '.'], ['it', 'takes', 'much', 'time', 'bag', 'groceries', '.'], ['especially', 'buying', 'family', '3', 'teenagers', '.'], ['seriously', 'considering', 'going', 'back', 'bee', 'caves', 'heb', 'on', '.'], ['they', 'extremely', 'busy', '2', 'people', 'bagging', '.'], ['maybe', 'something', 'grocery', 'stores', 'offer', 'anymore', '.....']]\n",
      "\n",
      "[['fyi', '...', 'i', 'live', 'wimberley', 'bulk', 'shopping', 'dripping', 'location', '.'], ['never', 'problem', 'before', ',', 'sunday', 'bought', 'wonton', 'wrappers', 'make', 'home', 'made', 'egg', 'rolls', '.'], ['tried', 'use', 'last', 'night', ',', 'opened', 'package', ',', 'rancid', '!'], ['the', 'date', 'said', '5/20/17', '.'], ['nevertheless', ',', 'rancid', '.'], ['buyer', 'beware', '.']]\n",
      "\n",
      "[['too', 'small', 'crowd']]\n",
      "\n",
      "[['really', 'busi']]\n",
      "\n",
      "[['big', 'store', ',', 'small', 'town', 'attitude', '.'], ['when', 'favorite', 'brand', 'discontinued', 'asked', 'manager', 'would', 'please', 'keep', 'shelf', 'me', '.'], ['they', 'did', '!'], ['that', \"'s\", 'common', 'day', 'age', 'big', 'stores', '.'], ['update', ',', 'lied', '.'], ['not', 'happy', '!']]\n",
      "\n",
      "[['it', 'annoying', '.'], ['been', 'waiting', '...', 'for', 'days', '!'], ['to', 'pick', 'rx', '.'], ['kept', 'told', ':', 'we', \"'re\", 'waiting', 'call', 'back', 'dr', 'refill', '...'], ['however', ',', 'sent', 'request', 'dr', 'retired', 'last', 'year', '.'], ['we', 'given', 'pharmacy', 'new', 'rx', 'new', 'dr', \"'s\", 'contact', 'info', 'several', 'occasions', '.'], ['but', ',', 'heb', 'pharmacy', 'says', 'info', 'rx', 'current', 'dr', '.'], ['so', 'go', 'again', '.'], ['have', 'get', 'new', 'rx', '....', 'again', '!'], ['so', ',', 'perhaps', 'feel', 'frustration', '.'], ['thank', 'you', '!'], ['2']]\n",
      "\n",
      "[['took', '20', 'minutes', 'finally', 'get', 'checked', 'out', '.'], ['the', 'two', 'cashier', \"'s\", 'deep', 'convo', 'going', 'on', '.']]\n",
      "\n",
      "[['worst', 'heb', 'ever', '.'], ['go', 'list', '8', 'normal', 'things', '4', 'them', '.'], ['they', 'stocked', 'overkill', 'heb', 'products', 'done', 'away', 'name', 'brands', '.'], ['produce', 'awful', '.'], ['they', 'say', 'everything', 'great', 'curbside', 'shopping', 'comes', 'in', '.'], ['joke', '!'], ['there', 'one', 'person', 'know', 'wants', 'one', 'workers', 'picking', 'groceries', '.'], ['can', 'wait', 'different', 'grocery', 'store', 'built', 'dripping', 'springs', '.'], ['maybe', 'then', ',', 'store', 'get', 'act', 'together', '.']]\n",
      "\n",
      "[['constantly', 'discontinuing', 'products', 'purchase', 'weekly', '.'], ['things', 'buy', 'heb', 'stores', ',', 'i', \"'m\", 'told', 'dripping', 'springs', 'store', 'longer', 'carry', '.'], ['this', 'happens', 'n', 'again', '.'], ['i', \"'ll\", 'drive', 'extra', '10', 'miles', 'shop', 'elsewhere', '.'], ['where', 'input', 'matters', '.']]\n",
      "\n",
      "[['meat', 'counter', 'trustworthy', '.'], ['ask', 'pay', 'one', 'thing', 'get', 'another', '.'], ['not', 'impressed', '.']]\n",
      "\n",
      "[['love', 'heb', 'one', 'frequently', 'stock', 'items', ',', 'carry', 'them', '.'], ['the', 'flower', 'department', 'limited', 'bakery', 'department', 'good', '.'], ['we', 'order', 'mini', 'wedding', 'cakes', 'always', 'good', '.'], ['hopefully', 'remodel', 'one', 'add', 'relevant', 'stuff', '.']]\n",
      "\n",
      "[['shelves', 'often', 'bare', '.'], ['they', 'feel', 'need', 'move', 'items', 'week', 'week', '.']]\n",
      "\n",
      "[['they', 'rude', '.'], ['done', 'shopping', 'went', 'deli', 'asked', 'rotisserie', 'chicken', 'said', 'right', 'rude', 'tone', '.'], ['30', 'minutes', 'late', 'still', 'went', 'che', 'k', 'leaving', 'brought', 'out', '.'], ['will', 'go', 'back', 'tomorrow', 'sucks', 'hate', 'location', 'staff', 'always', 'rud']]\n",
      "\n",
      "[['heb', 'big', ',', 'almost', 'monopoly', 'area', '.'], ['there', 'brand', ',', 'great', '.'], ['their', 'pricing', 'service', 'leaves', 'lot', 'desired', '.']]\n",
      "\n",
      "[['if', 'like', 'heb', 'branded', 'product', 'place', 'you', '.'], ['if', 'want', 'brands', 'grew', 'familiar', 'find', 'frustrated', 'visiting', 'heb', 'store', '.'], ['hopefully', 'heb', 'realizes', 'everyone', 'wants', 'cheapest', 'products', 'made', 'cater', 'brands', 'areas', 'demographic', 'little', 'better', '.'], ['know', 'types', 'product', 'sold', 'zeroing', 'brands', 'quality', 'products', 'sold', 'next', 'step', '.'], ['your', 'speed', 'bumps', 'ridiculous', '.']]\n",
      "\n",
      "[['this', 'far', 'worst', 'heb', 'hill', 'country', 'area', '.'], ['marble', 'falls', '(', 'new', 'store', ')', 'best', 'one', '.'], ['next', 'would', 'bulverde', '.'], ['then', 'would', 'say', 'fredericksburg', '.'], ['the', 'heb', 'dripping', 'springs', 'garbage', '.']]\n",
      "\n",
      "[['this', 'loaction', 'suck']]\n",
      "\n",
      "[['this', 'store', 'nasty', ',', 'cluttered', ',', 'does', 'room', 'qll', 'products', 'trying', 'sell', '.'], ['you', 'ca', \"n't\", 'find', 'want', ',', 'sorry', 'store', 'needs', 'remotel', 'makeover', '.'], ['the', 'prices', 'outrageous', ',', 'milk', '$', '1.78', 'heb', 'mont', 'belvieu', ',', 'want', '$', '2.98-', '$', '3.98', '.'], ['your', 'sushi', 'bar', 'product', '630pm', ',', '5-6', 'items', '.'], ['sad']]\n",
      "\n",
      "[['today', 'struggle', '.'], ['out', 'many', 'items', 'first', 'time', '.'], ['not', 'sure', 'boy', 'frustrating', '.'], ['looking', 'different', 'place', 'shop', '.']]\n",
      "\n",
      "[['good', 'heb', 'stand', 'staff', 'times', '.'], ['some', 'plain', 'rude', '.'], ['i', \"'m\", 'surprised', 'even', 'get', 'hired', 'first', 'place', '.'], ['well', 'meet', 'one', 'girl', ',', 'victoria', 'c.', 'super', 'rude', ',', 'manners', 'whatsoever', '!'], ['ask', '``', 'hey', ',', 'you', '?', \"''\"], ['looks', 'right', 'me', ',', 'knows', 'i', \"'m\", 'talking', 'gives', 'dirty', 'look', '.'], ['i', \"'ve\", 'never', 'met', 'person', 'life', '..', 'what', \"'s\", 'problem', '?'], ['then', 'bagging', 'groceries', 'literally', 'throwing', 'seriously', 'broke', '5', 'eggs', 'smashed', 'crackers', '.'], ['i', \"'d\", 'rather', 'bag', 'groceries', 'ways', '.'], ['should', 'told', 'leave', 'sh', '*', 't', 'alone', '.'], ['next', 'time', 'guess', 'i', \"'ll\", 'speak', 'up', '.'], ['hope', 'gets', 'stick', 'butt', 'gets', 'better', 'attitude', '.']]\n",
      "\n",
      "[['i', '’', 've', 'lived', '11', 'years', 'think', 'it', '’', 's', 'crying', 'shame', 'town', ',', 'given', 'avg', 'population', 'income', ',', 'gets', 'heb', 'scale', '.'], ['it', '’', 's', 'embarrassing', ',', 'heb', 'hq', '.'], ['know', 'fact', 'store', 'grosses', '$', '1m', 'per', 'week', 'crummy', 'little', 'store', '.'], ['product', 'availability', 'scarce', 'always', 'need', 'stocking', '.'], ['go', 'check', 'heb', 'buda', 'kyle', 'beecave', 'matter', '..', 'makes', 'store', 'look', 'like', 'red-headed', 'step', 'child', '.'], ['would', 'rather', 'travel', '30mi', 'one', 'way', 'shop', 'often', 'do', '.'], ['hope', 'review', 'gets', 'corporate', 'comfortable', 'bun', '$', 'expand', 'store', 'give', 'us', 'store', 'deserve', '!']]\n",
      "\n",
      "[['the', 'bathrooms', 'disgust']]\n",
      "\n",
      "[['insulting', 'highly', 'judgemental', '.'], ['profiling', 'employee', \"'s\", 'bad']]\n",
      "\n",
      "[['called', '7', 'different', 'heb', \"'s\", 'location', 'one', 'opening', 'daughter', \"'s\", 'wedding', 'date', '.'], ['the', 'florist', 'pleasant', 'deal', 'with', ',', 'return', 'phone', 'calls', 'emails', '.'], ['she', 'says', 'one', 'thing', 'another', '.'], ['sent', 'veronica', 'least', '10', 'emails', 'still', 'got', 'things', 'together', '.'], ['my', 'daughter', \"'s\", 'wedding', 'date', 'october', '20th', 'still', 'flowers', '.'], ['weddings', 'stressful', ',', 'especially', 'working', 'someone', 'says', 'one', 'thing', 'another', '.'], ['now', 'i', \"'m\", 'stuck', 'fresh', 'flowers', 'daughter', \"'s\", 'wedding', '.'], ['never', 'return', 'store', 'again', '.'], ['informed', 'wants', '320', 'dollar', 'delivery', 'fee', 'fo', 'venue', 'that', \"'s\", '15', 'miles', 'away', '.'], ['needless', 'say', 'still', 'florist', 'daughter', \"'s\", 'wedding', '.']]\n",
      "\n",
      "[['crowded', 'expens']]\n",
      "\n",
      "[['they', 'keep', 'cutting', 'number', 'items', 'stock', '.']]\n",
      "\n",
      "[['no', 'bread', ',', 'meats', ',', 'toilet', 'paper', ',', 'baby', 'wipes', ',', 'disinfectant', '!']]\n",
      "\n",
      "[['(', 'translated', 'google', ')', 'everything', 'dirty', 'people', 'cough', 'cover', 'mouths', '(', 'original', ')', 'todo', 'muy', 'sucio', 'la', 'gente', 'tose', 'se', 'tapa', 'la', 'boca']]\n",
      "\n",
      "[['this', 'latest', 'revelation', 'deal-killer', '.'], ['the', 'store', 'overrun', 'shoppers', ',', 'masks', ',', 'kids', 'running', 'wild', 'crowded', 'aisles', '.'], ['while', 'management', 'may', 'simply', 'prepared', 'regulate', 'shoppers', ',', 'could', 'regulate', 'practices', 'horrific', 'time', '.'], ['none', 'checkers', 'masks', 'gloves', '.'], ['social', 'distancing', 'unheard', 'of', '.'], ['no', 'sanitizer', 'readily', 'available', 'customers', \"'\", 'hands', '.'], ['it', 'cesspool', 'defiance', 'regarding', 'safe', 'practices', '.'], ['thank', 'goodness', '30-minute', 'drive', 'austin', '.'], ['just', 'called', 'sprouts', 'verified', 'checkers', 'shelf', 'stockers', 'wearing', 'basics', 'masks', 'gloves', '.'], ['oh', ',', 'yes', ',', 'are', '.'], ['distancing', 'strictly', 'enforced', '.'], ['funny', '20', 'miles', 'do', '.'], ['i', \"'ll\", 'happy', 'keep', 'austin', 'weird', '.']]\n",
      "\n",
      "[['we', 'bought', 'red', 'diamond', 'tea', 'went', 'bring', 'back', 'warn', 'pin', 'hole', 'it', '.'], ['the', 'girl', 'customer', 'service', 'rude', '!', '!', '!', '!', '!'], ['she', 'treated', 'husband', 'done', 'also', 'refused', 'trade', 'out', '!', '!', '!', '!'], ['check', 'tea', '....'], ['when', 'went', '2nd', 'one', 'bought', '🤦\\u200d♀️😳']]\n",
      "\n",
      "[['really', 'needed', 'plus', 'store', 'small', 'growing', 'area', '.']]\n",
      "\n",
      "[['the', 'number', 'people', 'shopping', 'without', 'masks', 'appalling', '.']]\n",
      "\n",
      "[['love', 'almost', 'employees', 'nothing', 'ever', 'wrong', 'them', ',', 'however', 'honest', 'issues', '.'], ['purchased', 'beer', 'heb', 'gone', 'bad', 'shelf', 'got', 'bad', 'food', 'poisoning', 'well', 'like', 'employees', 'i', \"'m\", 'afraid', 'one', 'two', 'cashiers', 'occasion', 'rude', '.'], ['now', 'know', 'work', 'anymore', 'time', 'one', 'older', 'woman', 'made', 'rude', 'comments', 'another', 'chatted', 'storm', 'person', 'front', 'moved', '40', 'item', 'cart', '15', 'limit', 'item', 'checkout', 'carts', 'behind', 'well', '.']]\n",
      "\n",
      "[['they', 'store', 'coupons', 'never', 'work', 'check', 'out', '.'], ['then', 'get', 'adtide', 'cashiers', '.'], ['you', 'dont', 'like', 'working', 'leave', 'otherwise', 'learn', 'term', 'customer', 'service', 'means', '.'], ['not', 'mention', 'inability', 'get', 'help', 'finding', 'things', '.'], ['heb', 'lost', 'way', 'loc']]\n",
      "\n",
      "[['some', 'customers', 'wear', 'mask', '.'], ['when', 'told', 'heb', 'worker', 'it', ',', 'said', 'allowed', 'tell', 'people', 'put', 'mask', '.']]\n",
      "\n",
      "[['this', 'heb', 'enforce', 'wearing', 'mask', 'store', 'regardless', 'huge', 'sign', 'stating', 'required', 'mask', 'store', '.'], ['at', 'point', 'either', 'part', 'solution', 'contributing', 'problem', '.'], ['this', 'store', 'flirting', 'complacency', 'issue', '.']]\n",
      "\n",
      "[['never', 'i', \"'m\", 'looking', 'for', '.....', 'their', 'pharmacy', 'best', '!']]\n",
      "\n",
      "[['diety', ',', 'expensive', ',', 'lacking', 'selection', '.']]\n",
      "\n",
      "[['frequent', 'shopper', 'last', 'several', 'visits', 'i', \"'ve\", 'disappointed', 'availability', 'items', '(', 'empty', 'shelves', ')', 'facing', 'stocked', 'items', '.'], ['know', 'due', 'pandemic', ',', 'stores', 'well', 'stocked', 'reasons', 'beyond', 'control', ',', 'i', \"'ve\", 'hebs', 'area', 'find', 'far', 'better', 'stocked', '.'], ['and', ',', 'shelves', 'front', 'shoppers', 'reach', 'get', 'items', '.'], ['many', 'times', 'i', \"'ve\", 'get', 'knees', 'reach', 'items', 'lower', 'shelf', 'way', 'back', '.'], ['as', 'many', 'times', 'i', \"'ve\", 'reach', 'top', 'shelf', ',', 'extra', 'items', 'are', ',', 'item', \"'s\", 'shelf', 'empty', '.'], ['just', 'today', ',', 'helped', 'customer', 'reach', 'top', 'shelf', '.'], ['frustrated', ',', 'shopping', 'wimberley', 'austin', 'find', 'access', 'everything', 'need', ',', 'even', 'away', '.']]\n",
      "\n",
      "[['because', 'managers', 'cashier', 'named', 'diana', ',', 'drive', 'wimberley', 'texas', 'grocery', 'shopping', '.'], ['go', 'brookshire', 'brothers', '.'], ['gladly', 'drive', '30', 'extra', 'minutes', 'avoid', 'rude', 'cashiers', 'like', 'diana', ',', 'zero', 'skills', 'friendly', 'lazy', 'managers', 'observe', 'laugh', 'giggle', 'instead', 'getting', 'hands', 'dirty', 'help', 'staff', '.']]\n",
      "\n",
      "[['1st', 'keep', 'mind', 'love', 'dripping', 'springs', 'heb', 'store', ',', 'nice', 'people', 'friendly', 'helpful', 'customers', 'say', 'always', 'one', 'bad', 'apple', 'bunch', '.'], ['the', 'store', 'opened', '6am', 'already', '7:30', 'overnight', 'stock', 'staff', 'still', 'working', 'isles', 'cram', 'packed', 'cases', 'product', 'lots', 'empty', 'boxes', '(', 'trash', ')', 'making', 'difficult', 'navigate', 'almost', 'every', 'isle', 'store', '.'], ['one', 'a-hole', 'guy', ',', 'came', 'patiently', 'waited', 'move', 'trash', 'could', 'get', 'looked', 'shook', 'head', 'disgust', 'clear', 'isle', '.'], ['to', 'rude', 'really', 'realize', 'shoppers', '(', 'in', 'grand', 'scheme', 'things', ')', 'pays', 'salary', '!'], ['where', 'would', 'without', 'customers', '?', '?'], ['heb', 'management', 'maybe', 'hold', 'training', 'session', 'people', 'let', 'know', 'show', 'courtesy', 'customers', 'much', 'checkers', 'staff', 'do', '..', 'just', 'hint', '.'], ['to', 'others', '(', 'not', 'a-hole', 'guy', ')', 'fantastic', 'job', 'champions', 'pandemic', 'coming', 'work', 'day', 'serving', 'us', '.'], ['thank', 'much']]\n",
      "\n",
      "[['hello', 'i', '’', 've', 'shopped', 'heb', 'dripping', 'springs', 'since', 'opened', 'years', 'ago', '.'], ['always', 'treated', 'well', 'exception', 'certain', 'cashier', 'named', 'diana', '.'], ['extreme', 'displeasure', 'diana', 'cashier', 'three', 'times', '.'], ['each', 'time', 'nothing', 'extremely', 'rude', ',', 'curt', ',', 'disrespectful', 'family', '.'], ['never', 'treated', 'poorly', 'heb', '.'], ['each', 'time', 'happened', ',', 'respectfully', 'communicated', 'issues', 'heb', 'management', ',', 'seem', 'baffled', 'claim', 'end', 'problem', '.'], ['seems', 'like', 'management', 'problem', 'diana', 'style', 'rude', 'people', '.'], ['diana', 'flip', 'burgers', 'instead', 'working', 'customers', '.'], ['take', 'business', 'elsewhere', '.'], ['afford', 'it', '.']]\n",
      "\n",
      "[['the', 'last', 'bagger', 'encountered', 'threw', 'produce', '(', 'apples', ',', 'potatoes', ',', 'onions', ')', 'random', 'bags', 'slipped', 'conveyor', 'belt', '-', 'noticed', 'saw', 'empty', 'produce', 'bag', 'onion', 'skins', 'shoved', 'side', '.'], ['asked', '(', 'to', 'show', 'manager', ')', 'threw', 'me', '.'], ['management', 'needs', 'get', 'younger', 'cashiers', 'baggers', '(', 'this', 'coming', '22', 'year', 'old', 'manners', ')', '-', 'oh', 'yeah', ',', 'expect', 'side', 'eyes', ',', 'phone', 'cashier', ',', 'overstuffing', 'bags', '.'], ['awful', 'customer', 'service', '.']]\n",
      "\n",
      "[['heb', ',', 'location', 'okay', '!'], ['managers', 'sit', 'around', ',', 'lines', ',', 'super', 'slow', ',', 'busy', 'heb', 'is', ',', 'think', 'would', 'fully', 'staffed', '.'], ['this', 'heb', 'really', 'needs', 'help', '.'], ['poorly', 'managed', 'store', '.'], ['called', 'store', 'girl', 'cs', 'desk', 'suggested', 'come', 'early', 'am', ',', 'typical', 'american', 'working', '.'], ['really', 'helpful', '.'], ['thanks', '.'], ['edit', ':', 'wow', 'heb', 'really', 'really', 'bad', '.']]\n",
      "\n",
      "[['there', 'nothing', 'wrong', 'store', 'self', '.'], ['cashier', \"'s\", 'friendly', '.'], ['pickers', 'little', 'rude', 'sometimes', '.'], ['but', 'always', 'packed', 'rudest', ',', 'try', 'run', 'people', '.'], ['even', 'parking', 'lot', '.'], ['it', 'pleasant', 'experience', '.'], ['been', 'going', 'wimberly', 'whole', 'different', 'experience', '.']]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize reviews (natural language to numerical value)\n",
    "# Library\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "# isolate reviews\n",
    "def isolate_reviews(store_df):\n",
    "    # Exclude stopwords\n",
    "    store_df['review_without_stopwords'] = store_df['review_text'].apply(\n",
    "        lambda x: ' '.join([word for word in x.split() if word not in (stop_word) and word not in (stop_word_upper)]))\n",
    "    return store_df\n",
    "\n",
    "def tokenize_review(review):\n",
    "    review_sentences = sent_tokenize(review)\n",
    "    ps = PorterStemmer() # reduce words to their root\n",
    "    review_stemmed = []\n",
    "    for word in review_sentences:\n",
    "        review_stemmed.append(ps.stem(word))\n",
    "    review_tokenized = []\n",
    "    for word in review_stemmed:\n",
    "        review_tokenized.append(word_tokenize(word))\n",
    "    return review_tokenized\n",
    "\n",
    "heb_dpsp_reviews = isolate_reviews(heb_dpsp_tx_df)\n",
    "\n",
    "for review in heb_dpsp_reviews[\"review_without_stopwords\"]:\n",
    "    token_review = tokenize_review(review)\n",
    "    print(token_review)\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
